First Job
1. To be or not to be: my journal from a geoscientist to data scientist, a self-intro
2. 2020 is eventful: prepare for the job market at the end of 2020 (First offer before Xmas)  
3. Interview is all about personal connection
4. Negotiation is everywhere    
5. Thanks to my family, friends, and Insight fellows
6. 2021 is even more eventful. (US Election, granny, company aquisition, company reorg)

### "But if you go there and do this modeling for your PhD, promise me one thing:   do NOT just do modeling.  Work somehow or be involved with the actual system that you are trying to model.   Know that system extremely well, physically and chemically.   Your models, which can be the main part of your work, will mean nothing unless you REALLY understand WHAT you are modeling.   Do you understand?   If you do that, your work will be twice as powerful." - Michael Hochella 2014

## 1. To be or not to be  
- Like most STEM PhD, my academic experience is pretty ordinary: college, graduate school, etc. It is worth mentioning that I have was looking for industry opportunities after my master graduation, which gave me a lot of exposure of how the world running outside of ivory tower. In terms of academic background, I am a bit of everything: performing experiment in laboratory as well as running modeling on high-performance computers. Experimentation, data analysis, modeling (debugging, tuning, and benchmarking), figure plotting (visualization), writing paper (storytelling), etc. are the typical routine for STEM research. All these experiences prepared my career as a data scientist.

- The trigger that made me took a leap of faith is the advise from my friends in data science: "3 months would be enough for a STEM PhD to start a career as a data scientsit." First, I used Kaggle and Andrew Ng's ML course on Coursera as a starter. Kaggle challenges helped me get familar with the basics of ML pipeline and Jupyter Notebook by following the receipt to bake my first project "Titanic". Andrew Ng's course is a classic, top-down approach, enjoyable to rewatch multiple times (Often you need to rewatch to truly understand what you are doing :P). While I was watching the course, I was continue practicing Kaggle Challenges. My second Kaggle Challenge is the house price prediction, which helped me to implment basic regression on Jupyter Notebook ("Titanic" is about classification). I took the next Kaggle Challenge much more seriously. I planned to use it as demo for my code interview of Insight Data Science Fellowship. So I wanted to understand every detail and started it from scratch. I delibrately chose the IEEE Fraud Detection so that I can take advantage of the expertise of my friends who are working in Fin-tech. On my GibHub, there are several versions reflecting how I levled-up this project gradually. (Side note: I have completed four Kaggle Challenges in total.) 

- My main takeaways from my starting period:
- -  1. Learning by doing. Taking course while practicing data challenges. It really suits my learning style, as an experimentalist, to grasp the nature of ML process through hands-on practice.
- -  2. Carefully selecting a project (e.g. in the domain you are familar with) and perfecting it wholeheartedly is a good learning experience.

- Insight Data Science and Citrine Informatics (to be continued)
