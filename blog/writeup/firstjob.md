# First Job
1. To be or not to be: my journal from a geoscientist to data scientist, a self-intro
2. 2020 is eventful: prepare for the job market at the end of 2020 (First offer before Xmas)  
3. Interview is all about personal connection
4. Negotiation is everywhere    
5. Thanks to my family, friends, and Insight fellows
6. 2021 is even more eventful. (US Election, granny, company aquisition, company reorg)

### "But if you go there and do this modeling for your PhD, promise me one thing:   do NOT just do modeling.  Work somehow or be involved with the actual system that you are trying to model.   Know that system extremely well, physically and chemically.   Your models, which can be the main part of your work, will mean nothing unless you REALLY understand WHAT you are modeling.   Do you understand?   If you do that, your work will be twice as powerful." - Michael Hochella 2014

## 1. To be or not to be  
- Like most STEM PhD, my academic experience is pretty ordinary: college, graduate school, etc. It is worth mentioning that I have was looking for industry opportunities after my master graduation, which gave me a lot of exposure of how the world running outside of ivory tower. In terms of academic background, I am a bit of everything: performing experiment in laboratory as well as running modeling on high-performance computers. Experimentation, data analysis, modeling (debugging, tuning, and benchmarking), figure plotting (visualization), writing paper (storytelling), etc. are the typical routine for STEM research. All these experiences prepared my career as a data scientist.

- The trigger that made me took a leap of faith is the advise from my friends in data science: "3 months would be enough for a STEM PhD to start a career as a data scientsit." First, I used Kaggle and Andrew Ng's ML course on Coursera as a starter. Kaggle challenges helped me get familar with the basics of ML pipeline and Jupyter Notebook by following the receipt to bake my first project "Titanic". Andrew Ng's course is a classic, top-down approach, enjoyable to rewatch multiple times (Often you need to rewatch to truly understand what you are doing :P). While I was watching the course, I was continue practicing Kaggle Challenges. My second Kaggle Challenge is the house price prediction, which helped me to implment basic regression on Jupyter Notebook ("Titanic" is about classification). I took the next Kaggle Challenge much more seriously. I planned to use it as demo for my code interview of Insight Data Science Fellowship. So I wanted to understand every detail and started it from scratch. I delibrately chose the IEEE Fraud Detection so that I can take advantage of the expertise of my friends who are working in Fin-tech. On my GibHub, there are several versions reflecting how I levled-up this project gradually. (Side note: I have completed four Kaggle Challenges in total.) 

- My main takeaways from my starting period:
- -  1. Learning by doing. Taking course while practicing data challenges. It really suits my learning style, as an experimentalist, to grasp the nature of ML process through hands-on practice.
- -  2. Carefully selecting a project (e.g. in the domain you are familar with) and perfecting it wholeheartedly is a good learning experience.

- First interview and Insight Data Science Fellowship  
   - The first applicaiton in data science was for Insight Data Science Fellowship (NYC cohort). My application was submitted in July 2020 and I had been preparing my interview ever since. Interesting, another opportunity showed up shortly afterwards, which interestingly led to my first interview. My first interview in data science was for the data scientist position from Citrine Informatics, where my college JS worked as a manager (not the hiring manager for this position though). 
- First interview for the data scientist position at Citrine Informatics (phone screening, 2 weeks data challenge and research writeup) 
  - This position should be a great fit since JS mentioned that an ideal candidate would be an expert in materials science with some knowledge about data science and machine learning. Plus, I enjoy our professional relationship through WastePD. So he would commend me internally as well as provide a strong referral. Therefore, it was an opportunity with high probability. I put more than 100% effort to prepare the interview, especially the data challenge. As expected, I passed the phone technical screen and proceeded to take the data challenge. To untackle this challenge, I read plenty papers and studied the patent by the company founder, plus the exhaustive deepdive. In terms of the formt, I followed the same format as the company's showcase report. In terms of the technical challenge, I incorporated the nobility index, one of latest findings in this area, as a new feature to improve the prediction. I published my work on nobility index [here](https://github.com/er1czz/elements). FYI, [private access of the whole data challenge](https://github.com/er1czz/citrine_challenge). The writeup was very well written (according to JS). However, this opportunity did not work out.  ``` A bi~g bummer  ¯\_(ツ)_/¯  ``` 
       - Takeaway, although it is a big frustration due to my high hope, I gained more confidence on myself: the data challenge reinforced my overall skills on both indepedent research and data science. It pushed me much hard in terms of the overall quality due to the high expection (high hope).  
   
- Insight Data Science (7-week program, September 14, 2020 to October 30, 2020) 
- 
